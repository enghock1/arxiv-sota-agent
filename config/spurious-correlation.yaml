benchmark_name: "Spurious Correlation Benchmark"

### step 1: parameters used for scanning and filtering arxiv metadata database ###
ARXIV_METADATA_SCANNING_PARAMETERS:
  
  # maximum number of metadata entries to scan from the arxiv dataset (-1 = no limit)
  max_metadata_scan_limit: -1  

  # Only allow these arxiv categories
  allowed_categories: ["cs.LG", "stat.ML", "cs.AI"]
  
  # Minimum publication date (YYYY-MM-DD)
  min_date: "2015-01-01"
  
  # Exclude non-technical papers based on title keywords
  exclude_title_keywords: 
    - "survey"
    - "review"
    - "comprehensive"
  
  # Is the paper published? (by checking if doi exist)
  is_published: false

  # keywords to search for in title/abstract
  title_abstract_keywords:
    - "spurious correlation"


### Step 2: parameters used for downloading arxiv LaTeX sources ###
ARXIV_SOURCE_DOWNLOAD_PARAMETERS:
  
  # maximum number of ArXiv download calls. (-1 = no limit)
  max_arxiv_calls: 500

  # whether to store the downloaded LaTeX source files in data/sources/ dir.
  keep_latex_source: false  

  # whether to save parsed papers after downloading. Will save in data/parsed_papers/ dir.
  save_parsed_papers: true

  # whether to preview the first 10 parsed papers after downloading. Will save in data/processed/ dir.
  preview_parsed_papers: true


### Step 3: parameters used for scanning and filtering parsed papers ###
PARSED_PAPER_SCANNING_PARAMETERS:

  # keywords to search for in parsed paper content (sections)
  content_keywords:
    - "Waterbirds"

MODEL_NAME: "gemini-3-flash-preview"

pipeline_stages: 
  - "Data-Centric" # data augmentation, balancing, reweighting
  - "Representation Learning" # invariant learning, contrastive learning, feature disentanglement
  - "Post-hoc Methods" # finetuning, ensemble learning, calibration
  - "Others"

extraction_goals:
  primary_metric: "Worst-Group Accuracy"
  primary_metric_description: "Lowest accuracy across anny subgroup."