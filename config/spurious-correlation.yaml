benchmark_name: "Spurious Correlation Benchmark"

### step 1: parameters used for scanning and filtering arxiv metadata database ###
ARXIV_METADATA_SCANNING_PARAMETERS:
  
  # maximum number of metadata entries to scan from the arxiv dataset (-1 = no limit)
  max_metadata_scan_limit: -1  

  # Only allow these arxiv categories
  allowed_categories: ["cs.LG", "stat.ML", "cs.AI"]
  
  # Minimum publication date (YYYY-MM-DD)
  min_date: "2015-01-01"
  
  # Exclude non-technical papers based on title keywords
  exclude_title_keywords: 
    - "survey"
    - "review"
    - "comprehensive"
  
  # Is the paper published? (by checking if doi exist)
  is_published: false

  # keywords to search for in title/abstract
  title_abstract_keywords:
    - "spurious correlation"


### Step 2: parameters used for downloading arxiv LaTeX sources ###
ARXIV_SOURCE_DOWNLOAD_PARAMETERS:
  
  # maximum number of ArXiv download calls. (-1 = no limit)
  max_arxiv_calls: -1

  # whether to store the downloaded LaTeX source files in data/sources/ dir.
  keep_latex_source: false  

  # whether to save parsed papers after downloading. Will save in data/parsed_papers/ dir.
  save_parsed_papers: true

  # whether to preview the first 10 parsed papers after downloading. Will save in data/processed/ dir.
  preview_parsed_papers: true


### Step 3: parameters used for scanning and filtering parsed papers ###
PARSED_PAPER_SCANNING_PARAMETERS:

  # keywords to search for in parsed paper content (sections)
  content_keywords:
    - "Waterbirds"


### Step 4: parameters used for LLM extraction phase ###
LLM_EXTRACTION_PARAMETERS:

  # model name to use for extraction
  model_name: "gemini-3-flash-preview"

  max_llm_calls: 5

  selected_dataset_names:
    - "Waterbirds"

  pipeline_stages: 
    - "Data-Centric" # data augmentation, balancing, reweighting
    - "Representation Learning" # invariant learning, contrastive learning, feature disentanglement
    - "Post-hoc Methods" # finetuning, ensemble learning, calibration
    - "Others"

  # performance metric to extract. key = metric name, value = metric description
  metrics:
    "Worst-Group Accuracy": "Lowest accuracy across anny subgroup."