benchmark_name: "Spurious Correlation Benchmark"

### step 1: parameters used for scanning and filtering arxiv metadata database ###
ARXIV_METADATA_SCANNING_PARAMETERS:
  
  # maximum number of metadata entries to scan from the arxiv dataset (-1 = no limit)
  max_metadata_scan_limit: -1  

  # Only allow these arxiv categories
  allowed_categories: ["cs.LG", "stat.ML", "cs.AI"]
  
  # Minimum publication date (YYYY-MM-DD)
  min_date: "2015-01-01"
  
  # Exclude non-technical papers based on title keywords
  exclude_title_keywords: 
    - "survey"
    - "review"
    - "comprehensive"
  
  # Is the paper published? (by checking if doi exist)
  is_published: false

  # keywords to search for in title/abstract
  title_abstract_keywords:
    - "spurious correlation"


### Step 2: parameters used for downloading arxiv LaTeX sources ###
ARXIV_DOWNLOAD_PARAMETERS:

  # maximum number of ArXiv download calls. (-1 = no limit)
  max_download_calls: 50

  # whether to store the downloaded PDF files in data/sources/ dir.
  save_files: true

  # whether to save parsed papers after downloading. Will save in data/parsed_papers/ dir.
  save_parsed_papers: true



### Step 3: parameters used for scanning and filtering parsed papers ###
# For "latex" mode: scans parsed LaTeX sections for keywords
# For "pdf" mode: scans first 10 pages of PDF for keywords
PARSED_PAPER_SCANNING_PARAMETERS:

  # keywords to search for in parsed paper content (sections for LaTeX, first 10 pages for PDF)
  content_keywords:
    - "Waterbirds"

  # whether to preview parsed papers after downloading. Will save in data/processed/ dir.
  preview_filtered_papers: true

  


### Step 4: parameters used for LLM extraction phase ###
LLM_EXTRACTION_PARAMETERS:

  # model name to use for extraction
  model_name: "gemini-2.5-flash"

  max_llm_calls: 10

  selected_dataset_names:
    - "Waterbirds"

  pipeline_stages: 
    - "Data-Centric" # data augmentation, balancing, reweighting
    - "Representation Learning" # invariant learning, contrastive learning, feature disentanglement
    - "Post-hoc Methods" # finetuning, ensemble learning, calibration
    - "Others"

  # performance metric to extract. key = metric name, value = metric description
  metrics:
    "Worst-Group Accuracy": "Lowest accuracy across anny subgroup."